title: Hadoop 2.6.4集群部署
date: 2016-03-03 00:00:00
categories: Hadoop
tags: [Hadoop2.6.4, Big Data, Deploy]
description: 欢迎来到Hadoop的世界<br><br><img src="/images/hadoop/hadoop.jpg" alt="hadoop"><br>详细Hadoop 2.6.4集群部署请阅读全文
---

## 1. 运行环境  

JDK和Hadoop版本：

- JDK：1.8.0_74 64位
- Hadoop 2.6.4

## 2. 安装vim

vim是我个人比较熟悉的文本编辑器，系统中默认有vi或者gedit，如果对这些熟悉，可不用安装vim  

	sudo apt-get install vim  

## 3. 更改主机名

更改主机名是为了使集群中的机器更为方便识别，通常为master, slaver1, slaver2...或者hadoop1, hadoop2, hadoop3...格式，本文采用第二种格式。  

	sudo vim /etc/hostsname

## 4. 更改主机解析地址

为了使集群更好管理，通常将各个节点的IP设为局域网IP，步骤为：  

- 新建以太网
- 选择IPV4，手动
- 地址：192.168.1.X 子网掩码：255.255.255.0 网关：192.168.1.1
- 重启网络：sudo /etc/init.d/networking restart   

		sudo vim /etc/hosts

		192.162.1.10 hadoop1
		192.168.1.20 hadoop2
		192.168.1.30 hadoop3
		192.168.1.40 hadoop4	

## 5. 创建hadoop-group用户组和hadoop用户  
### 5.1 新建hadoop－group用户组  
	sudo addgroup hadoop-group

### 5.2 新建hadoop用户并加入到hadoop-group用户组中
	sudo adduser --ingroup hadoop-group hadoop

### 5.3 给hadoop用户赋予root权限
	sudo vim /etc/sudoers

	root ALL=(ALL:ALL) ALL
	hadoop ALL=(ALL:ALL) ALL

## 6. 安装SSH
### 6.1 更新apt-get
	sudo apt-get update

### 6.2 安装openssh-server服务
	sudo apt-get install openssh-server

### 6.3 建立ssh免密码登录各节点
1. 创建ssh-key

		ssh-keygen -t rsa -P ""

2. 对于master,进入~/.ssh/目录下，将id_rsa.pub追加到authorized_keys授权文件中	

		cat id_rsa.pub >> authorized_keys	或
		cp id_rsa.pub authorized_keys

3. 对于slaver节点，将master的authorized_keys复制到~/.ssh目录下。同时设置属性如下：

		chmod 600 authorized_key //改变文件的权限为600
		chgrp hadoop-group authorized_keys //改变文件所属用户组
		chown hadoop authorized_keys //改变文件所属用户

4. 关闭防火墙

		sudo ufw disable

5. 测试从节点，并退出

		ssh hadoop2
		exit

### 6.4 配置文件

ssh的配置文件文件在/etc/ssh/sshd_config

### 6.5 注意

如果当前已有节点更新了机器名，则需要把~/.ssh/文件下的known_hosts文件删除，重新记录节点，否则有可能会信息冲突。

## 7. 安装JDK
### 7.1 解压缩
1. 在/home/hadoop/下新建java目录

		mkdir java
2. 将jdk-8u40-linux-i586.tar.gz文件解压至目标文件夹

		sudo tar -xzvf jdk-8u40-linux-i586.tar.gz -C /home/hadoop/java

### 7.2 配置环境变量

1. 打开./bashrc文件

		vim ~/.bashrc

	注意：/etc/profile为全局配置文件，配置后对所有用户生效；~/.bashrc为用户局部配置文
	件，只对当前用户生效。

2. 添加如下变量

		export JAVA_HOME=/home/hadoop/java/jdk1.8.0_74    
		export JRE_HOME=/home/hadoop/java/jdk1.8.0_74/jre      
		export CLASSPATH=.:$JAVA_HOME/lib:$JRE_HOME/lib:$CLASSPATH    
		export PATH=$JAVA_HOME/bin:$JRE_HOME/bin:$JAVA_HOME:$PATH 

3. 使该文件生效

		source ~/.bashrc

### 7.3 检查是否安装成功

	java -version

### 7.4 向各节点复制jdk安装文件及配置文件

	scp -r /home/hadoop/java hadoop@hadoop2:/home/hadoop/
	scp -r /home/hadoop/.bashrc hadoop@hadoop2:/home/hadoop/

## 8. 安装hadoop
### 8.1 解压缩

	sudo tar -xzvf hadoop-2.6.4.tar.gz -C ~/
	
### 8.2 修改hadoop配置文件

1. hadoop-env.sh

		export JAVA_HOME=/home/hadoop/java/jdk1.8.0_74

2. core-site.xml

		<configuration>
			<property>
				<name>fs.defaultFS</name>
				<value>hdfs://Master:9000</value>
			</property>
			<property>
				<name>io.file.buffer.size</name>
				<value>131072</value>
			</property>
			<property>
				<name>hadoop.tmp.dir</name>
				<value>file:/home/hadoop/tmp</value>
				<description>Abase for other temporary directories.</description>
			</property>
			<property>
				<name>hadoop.proxyuser.hduser.hosts</name>
				<value>*</value>
				</property>
			<property>
				<name>hadoop.proxyuser.hduser.groups</name>
				<value>*</value>
			</property>
		</configuration>

3. hdfs-site.xml

		<configuration>
			<property>
				<name>dfs.namenode.secondary.http-address</name>
				<value>Master:9001</value>
			</property>
			<property>
				<name>dfs.namenode.name.dir</name>
				<value>file:/home/hadoop/dfs/name</value>
			</property>
			<property>
				<name>dfs.datanode.data.dir</name>
				<value>file:/home/hadoop/dfs/data</value>
			</property>
			<property>
				<name>dfs.replication</name>
				<value>1</value>
			</property>
			<property>
				<name>dfs.webhdfs.enabled</name>
				<value>true</value>
			</property>
		</configuration>

4. mapred-site.xml.template重命名为mapred-site.xml

		<configuration>
			<property>
				<name>mapreduce.framework.name</name>
				<value>yarn</value>
			</property>
			<property>
				<name>mapreduce.jobhistory.address</name>
				<value>Master:10020</value>
			</property>
			<property>
				<name>mapreduce.jobhistory.webapp.address</name>
				<value>Master:19888</value>
			</property>
		</configuration>

5. yarn-site.xml

		<configuration>
			<property>
				<name>yarn.nodemanager.aux-services</name>
				<value>mapreduce_shuffle</value>
			</property>
			<property>
				<name>yarn.nodemanager.aux-services.mapreduce.shuffle.class</name>
				<value>org.apache.hadoop.mapred.ShuffleHandler</value>
			</property>
			<property>
				<name>yarn.resourcemanager.address</name>
				<value>Master:8032</value>
			</property>
			<property>
				<name>yarn.resourcemanager.scheduler.address</name>
				<value>Master:8030</value>
			</property>
			<property>
				<name>yarn.resourcemanager.resource-tracker.address</name>
				<value>Master:8031</value>
			</property>
			<property>
				<name>yarn.resourcemanager.admin.address</name>
				<value>Master:8033</value>
			</property>
			<property>
				<name>yarn.resourcemanager.webapp.address</name>
				<value>Master:8088</value>
			</property>
		</configuration>

### 8.3 添加hadoop路径到./bashrc

	export HADOOP_HOME=/home/hadoop/hadoop
	export PATH=$PATH:$HADOOP_HOME/bin

### 8.4 修改slavers文件

添加slaver节点机器名（hadoop2, hadoop3, hadoop4 ...）到slavers文件中

### 8.5 向各从节点复制hadoop

	scp -r /home/hadoop/hadoop-2.6.4 hadoop@hadoop2:/home/hadoop/
	scp -r /home/hadoop/hadoop-2.6.4 hadoop@hadoop3:/home/hadoop/

### 8.6 在hadoop1节点上格式化hdfs

	bin/hdfs namenode -format

### 8.7 启动hdfs

	sbin/start-dfs.sh

### 8.8 启动yarn

	sbin/start-yarn.sh

### 8.9 jps查看进程

1. hadoop1节点

		Jps
		NameNode
		SecondaryNameNode
		ResourceManager

2. 其他节点

		Jps
		NodeManager
		DataNode

### 8.10 注意事项

1. 如果需要重新格式化namenode,需要把各节点主目录下的dfs,tmp文件夹删除
2. 以上hadoop配置文件只是部分范例，在实际应用中，应该根据集群规模配置，还有很多配置细节需要进一步掌握。

## 9. 测试

### 9.1 Web UI

	http://hadoop1:50070

### 9.2 命令行

1. 查看DataNode信息

		bin/hdfs dfsadmin -report

2. 使Datanode节点退役

		 bin/hadoop dfsadmin -decommission datanodename

3. 集群置于安全模式下

		bin/hadoop dfsadmin -safenode enter

4. 集群关闭安全模式

		bin/hadoop dfsadmin -safenode leave

5. 帮助

		bin/hadoop dfsadmin -help

### 9.3 WordCount

	bin/hdfs dfs -put /home/hadoop/desktop/testfile /input
	bin/hadoop jar ~/hadoop-2.6.4/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.4.jar wordcount /input/ /output/wordcount

## 10 其他

1. 权限不够时，将文件所属改为hadoop
	
		chgrp users (-R) document //改变文件所用户组
		chown user (-R) document //改变文件所有者
		chmod 755 (-R) document //改变文件的权限

2. hdfs文件的相关的命令

		hdfs://hadoop1:9000/       hdfs根目录
		bin/hdfs dfs -mkdir /input   在hdfs上新建一个input文件夹
		bin/hdfs dfs -copyFromLocal /localdata /input  或
		bin/hdfs dfs -put /localdata /input   上传本地文件到hdfs的input文件夹下
		bin/hdfs dfs -cat /output/wordcount/* 查看wordcount下的文件  

3. 安装htop可以查看系统进程信息

		sudo apt-get install htop